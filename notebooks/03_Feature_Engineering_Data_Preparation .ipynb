{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsflsPaGli0t"
      },
      "source": [
        "# Feature Engineering & Data Preparation\n",
        "\n",
        "## Purpose\n",
        "\n",
        "This notebook transforms the FNB customer dataset into model-ready features for churn prediction. The feature engineering draws directly from EDA insights to create predictive signals.\n",
        "\n",
        "Key transformations:\n",
        "- Age-based risk indicators (45+ cohort showed 50.6% churn)\n",
        "- Product complexity scoring (U-shaped pattern: 2 products optimal, 3-4 catastrophic)\n",
        "- Geographic risk flags (Limpopo, Eastern Cape, Mpumalanga at 32-34% churn)\n",
        "- Financial ratios and engagement metrics\n",
        "- Customer lifetime value estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpFhlu3Bli0u"
      },
      "source": [
        "## Section 1: Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g-ZP_EWRli0v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Preprocessing tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# FNB colors\n",
        "fnb_blue = '#003D7A'\n",
        "fnb_gold = '#FFB81C'\n",
        "\n",
        "# Settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGu_DnLjli0w"
      },
      "source": [
        "## Section 2: Data Loading\n",
        "\n",
        "Loading the transformed dataset. This is the same data used in EDA, so we know its structure and quality characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD6AgLxili0w",
        "outputId": "fd91b7af-fb08-443c-f82d-cc180be23d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: 10,000 customers, 43 features\n",
            "Baseline churn rate: 20.4%\n",
            "Class balance: 3.9:1 (retained:churned)\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"Churn_Modelling_SA_FNB.csv\")\n",
        "\n",
        "print(f\"Loaded: {df.shape[0]:,} customers, {df.shape[1]} features\")\n",
        "print(f\"Baseline churn rate: {df['Churned'].mean():.1%}\")\n",
        "print(f\"Class balance: {df['Churned'].value_counts()[0] / df['Churned'].value_counts()[1]:.1f}:1 (retained:churned)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx-dTcG5li0w",
        "outputId": "4fc58b5e-5427-441c-db0d-f0fe66b52b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values check:\n",
            "No missing values\n"
          ]
        }
      ],
      "source": [
        "# Verify data quality\n",
        "print(\"Missing values check:\")\n",
        "missing = df.isnull().sum()\n",
        "if missing.sum() == 0:\n",
        "    print(\"No missing values\")\n",
        "else:\n",
        "    print(missing[missing > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9QNC6W0li0w"
      },
      "source": [
        "## Section 3: Feature Engineering Based on EDA Insights\n",
        "\n",
        "Creating features that capture the churn patterns identified in EDA. Each feature is motivated by a specific finding from the exploratory analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfR7aifIli0x"
      },
      "source": [
        "### Age-Based Features\n",
        "\n",
        "EDA showed age as the strongest predictor (Cohen's d = 0.739). The 46-55 cohort had 50.6% churn vs 20.4% baseline. Creating features to capture this non-linear age effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzbLj0gyli0x",
        "outputId": "152c133e-472f-4058-e3a5-ee7f9d42371d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age-based features created:\n",
            "  Age_Group distribution:\n",
            "Age_Group\n",
            "18-25     611\n",
            "26-35    3542\n",
            "36-45    3736\n",
            "46-55    1311\n",
            "56-65     536\n",
            "65+       264\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  High-risk age (45+): 2,340 customers (23.4%)\n"
          ]
        }
      ],
      "source": [
        "# Age group bins based on EDA findings\n",
        "df['Age_Group'] = pd.cut(\n",
        "    df['Age'],\n",
        "    bins=[0, 25, 35, 45, 55, 65, 100],\n",
        "    labels=['18-25', '26-35', '36-45', '46-55', '56-65', '65+']\n",
        ")\n",
        "\n",
        "# High-risk age flag (45+)\n",
        "df['Is_High_Risk_Age'] = (df['Age'] >= 45).astype(int)\n",
        "\n",
        "# Age squared for non-linear effects\n",
        "df['Age_Squared'] = df['Age'] ** 2\n",
        "\n",
        "print(\"Age-based features created:\")\n",
        "print(f\"  Age_Group distribution:\\n{df['Age_Group'].value_counts().sort_index()}\")\n",
        "print(f\"\\n  High-risk age (45+): {df['Is_High_Risk_Age'].sum():,} customers ({df['Is_High_Risk_Age'].mean():.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD5t8JE_li0x"
      },
      "source": [
        "### Product Complexity Features\n",
        "\n",
        "EDA revealed U-shaped churn: 1 product (27.7%), 2 products (7.6%), 3 products (82.7%), 4 products (100%). Creating features to flag these patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltJ2kUEsli0x",
        "outputId": "b96d4de4-cdac-45be-81c6-a428460ac6e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product complexity features:\n",
            "  Single product: 5,084 customers\n",
            "  Optimal (2): 4,590 customers\n",
            "  Over-banked (3-4): 326 customers\n"
          ]
        }
      ],
      "source": [
        "# Single product flag (under-engaged)\n",
        "df['Is_Single_Product'] = (df['NumOfProducts'] == 1).astype(int)\n",
        "\n",
        "# Optimal products flag (2 products)\n",
        "df['Is_Optimal_Products'] = (df['NumOfProducts'] == 2).astype(int)\n",
        "\n",
        "# Over-banked flag (3-4 products)\n",
        "df['Is_Over_Banked'] = (df['NumOfProducts'] >= 3).astype(int)\n",
        "\n",
        "# Product complexity score\n",
        "# Higher score for extremes (1 or 4 products), lower for optimal (2)\n",
        "product_risk_map = {1: 2.0, 2: 0.5, 3: 3.0, 4: 4.0}\n",
        "df['Product_Risk_Score'] = df['NumOfProducts'].map(product_risk_map)\n",
        "\n",
        "print(\"Product complexity features:\")\n",
        "print(f\"  Single product: {df['Is_Single_Product'].sum():,} customers\")\n",
        "print(f\"  Optimal (2): {df['Is_Optimal_Products'].sum():,} customers\")\n",
        "print(f\"  Over-banked (3-4): {df['Is_Over_Banked'].sum():,} customers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpE5lRSOli0x"
      },
      "source": [
        "### Financial Profile Features\n",
        "\n",
        "EDA showed churned customers have higher balances (R1.87M vs R1.49M). Creating ratio features and wealth indicators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBaByrQ0li0x",
        "outputId": "791af057-4a7e-48e9-ed5a-4aa5634be459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Financial features created:\n",
            "  Zero balance: 3,617 customers\n",
            "  High value (R2M+): 4,968 customers\n",
            "  Balance quartile distribution:\n",
            "Balance_Quartile\n",
            "1    2500\n",
            "2    2500\n",
            "3    2500\n",
            "4    2500\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Balance to salary ratio\n",
        "df['Balance_to_Salary_Ratio'] = df['Balance_ZAR'] / (df['AnnualSalary_ZAR'] + 1)  # +1 to avoid division by zero\n",
        "\n",
        "# Zero balance flag\n",
        "df['Has_Zero_Balance'] = (df['Balance_ZAR'] == 0).astype(int)\n",
        "\n",
        "# High value customer (balance > R2M)\n",
        "df['Is_High_Value'] = (df['Balance_ZAR'] >= 2_000_000).astype(int)\n",
        "\n",
        "# Balance quartiles\n",
        "try:\n",
        "    df['Balance_Quartile'] = pd.qcut(df['Balance_ZAR'].rank(method='first'), q=4, labels=False, duplicates='drop') + 1\n",
        "except ValueError:\n",
        "    # Fallback if qcut fails due to duplicate edges\n",
        "    df['Balance_Quartile'] = pd.cut(df['Balance_ZAR'], bins=4, labels=False) + 1\n",
        "\n",
        "print(\"Financial features created:\")\n",
        "print(f\"  Zero balance: {df['Has_Zero_Balance'].sum():,} customers\")\n",
        "print(f\"  High value (R2M+): {df['Is_High_Value'].sum():,} customers\")\n",
        "print(f\"  Balance quartile distribution:\\n{df['Balance_Quartile'].value_counts().sort_index()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36iIcJPSli0y"
      },
      "source": [
        "### Engagement Features\n",
        "\n",
        "EDA showed inactive members churn at 26.9% vs 14.3% for active. Digital adoption showed minimal impact, but creating engagement composite anyway."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC6Ab1MZli0y",
        "outputId": "64d6b697-15fb-43e9-cd6c-6852b445fe0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engagement features:\n",
            "  Digitally engaged (both channels): 5,602 customers\n",
            "  Has complaints: 3,907 customers\n"
          ]
        }
      ],
      "source": [
        "# Digital adoption score (0-2)\n",
        "df['Digital_Adoption_Score'] = df['UsesMobileBanking'] + df['UsesInternetBanking']\n",
        "\n",
        "# Digitally engaged flag\n",
        "df['Is_Digitally_Engaged'] = (df['Digital_Adoption_Score'] == 2).astype(int)\n",
        "\n",
        "# Service friction score (complaints + high service calls)\n",
        "df['Service_Friction_Score'] = df['Complaints_12M'] + (df['CustomerServiceCalls_12M'] > 3).astype(int)\n",
        "\n",
        "# Has complaints flag\n",
        "df['Has_Complaints'] = (df['Complaints_12M'] > 0).astype(int)\n",
        "\n",
        "print(\"Engagement features:\")\n",
        "print(f\"  Digitally engaged (both channels): {df['Is_Digitally_Engaged'].sum():,} customers\")\n",
        "print(f\"  Has complaints: {df['Has_Complaints'].sum():,} customers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD9wgH-oli0y"
      },
      "source": [
        "### Tenure-Based Features\n",
        "\n",
        "EDA showed tenure doesn't differentiate churn (19-23% across all cohorts), but including for completeness and potential interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiDQlZ-2li0y",
        "outputId": "c19289da-8443-467c-ba1d-a504aede0246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenure features:\n",
            "  New customers (<=1 year): 1,448\n",
            "  Tenure quartile distribution:\n",
            "Tenure_Quartile\n",
            "1    3505\n",
            "2    2001\n",
            "3    1995\n",
            "4    2499\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Tenure quartiles\n",
        "try:\n",
        "    df['Tenure_Quartile'] = pd.qcut(df['Tenure'], q=4, labels=False, duplicates='drop') + 1\n",
        "except ValueError:\n",
        "    df['Tenure_Quartile'] = pd.cut(df['Tenure'], bins=4, labels=False) + 1\n",
        "\n",
        "# New customer flag (tenure <= 1 year)\n",
        "df['Is_New_Customer'] = (df['Tenure'] <= 1).astype(int)\n",
        "\n",
        "# Tenure to age ratio (relationship maturity relative to age)\n",
        "df['Tenure_to_Age_Ratio'] = df['Tenure'] / (df['Age'] + 1)\n",
        "\n",
        "print(\"Tenure features:\")\n",
        "print(f\"  New customers (<=1 year): {df['Is_New_Customer'].sum():,}\")\n",
        "print(f\"  Tenure quartile distribution:\\n{df['Tenure_Quartile'].value_counts().sort_index()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B85fHAQtli0y"
      },
      "source": [
        "### Geographic Risk Features\n",
        "\n",
        "EDA showed Limpopo (34%), Eastern Cape (32%), Mpumalanga (31%) with elevated churn vs Gauteng/KZN at 15%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i5RTaNuli0z",
        "outputId": "5dbf0235-3977-40e3-d5b6-0118ab121595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geographic features:\n",
            "  High-risk province customers: 2,509\n",
            "  High-risk provinces: Limpopo, Eastern Cape, Mpumalanga\n"
          ]
        }
      ],
      "source": [
        "# High-risk province flag\n",
        "high_risk_provinces = ['Limpopo', 'Eastern Cape', 'Mpumalanga']\n",
        "df['Is_High_Risk_Province'] = df['Province'].isin(high_risk_provinces).astype(int)\n",
        "\n",
        "print(\"Geographic features:\")\n",
        "print(f\"  High-risk province customers: {df['Is_High_Risk_Province'].sum():,}\")\n",
        "print(f\"  High-risk provinces: {', '.join(high_risk_provinces)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjdqo3YIli0z"
      },
      "source": [
        "### Credit Risk Features\n",
        "\n",
        "EDA showed credit score has minimal impact (Cohen's d = -0.067), but creating tiers for completeness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghUqu-N-li0z",
        "outputId": "19b35020-5447-4ce6-842c-f4eb03d66d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credit features:\n",
            "  Poor credit (<600): 3,034 customers\n",
            "  Credit tier distribution:\n",
            "Credit_Risk_Tier\n",
            "Poor         3066\n",
            "Fair         1871\n",
            "Good         1947\n",
            "Excellent    3116\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Credit score tiers\n",
        "df['Credit_Risk_Tier'] = pd.cut(\n",
        "    df['CreditScore'],\n",
        "    bins=[0, 600, 650, 700, 850],\n",
        "    labels=['Poor', 'Fair', 'Good', 'Excellent']\n",
        ")\n",
        "\n",
        "# Poor credit flag\n",
        "df['Is_Poor_Credit'] = (df['CreditScore'] < 600).astype(int)\n",
        "\n",
        "print(\"Credit features:\")\n",
        "print(f\"  Poor credit (<600): {df['Is_Poor_Credit'].sum():,} customers\")\n",
        "print(f\"  Credit tier distribution:\\n{df['Credit_Risk_Tier'].value_counts().sort_index()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIwk2l4Zli0z"
      },
      "source": [
        "### Composite Risk Score\n",
        "\n",
        "Creating a composite risk score based on validated churn drivers from Advanced EDA. This mirrors the rule-based score but will compete with ML models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ckTG3Yqli0z",
        "outputId": "b7e645ee-7f8d-4c97-efbf-c00da4aca6cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Composite Risk Score:\n",
            "  Mean: 2.71\n",
            "  Median: 2.50\n",
            "  Range: 0.0 to 12.5\n"
          ]
        }
      ],
      "source": [
        "# Composite risk score (weighted sum of risk factors)\n",
        "df['Composite_Risk_Score'] = (\n",
        "    df['Is_High_Risk_Age'] * 3.0 +                # Age 45+ (strongest predictor)\n",
        "    df['HasPersonalLoan'] * 2.5 +                 # Personal loan (85.9% churn)\n",
        "    df['Is_Over_Banked'] * 2.5 +                  # 3-4 products (83-100% churn)\n",
        "    (1 - df['IsActiveMember']) * 2.0 +            # Inactive (26.9% vs 14.3%)\n",
        "    df['Is_High_Risk_Province'] * 1.5 +           # Limpopo/EC/Mpumalanga\n",
        "    df['Is_High_Value'] * 1.0                     # High balance (counter-intuitive but validated)\n",
        ")\n",
        "\n",
        "print(\"Composite Risk Score:\")\n",
        "print(f\"  Mean: {df['Composite_Risk_Score'].mean():.2f}\")\n",
        "print(f\"  Median: {df['Composite_Risk_Score'].median():.2f}\")\n",
        "print(f\"  Range: {df['Composite_Risk_Score'].min():.1f} to {df['Composite_Risk_Score'].max():.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSoyjIdPli0z"
      },
      "source": [
        "### Customer Lifetime Value (CLV)\n",
        "\n",
        "Estimating CLV for business impact analysis. Using simplified model: tenure-based revenue + balance-based margin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnyWtkomli0z",
        "outputId": "3f51d936-9124-46b5-efe3-20f4b3a60288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLV Estimation:\n",
            "  Mean CLV (5-year): R281,359\n",
            "  Total customer base CLV: R2,813.6M\n"
          ]
        }
      ],
      "source": [
        "# CLV estimation\n",
        "avg_annual_revenue = 50_000  # Conservative estimate per customer\n",
        "balance_margin = 0.02        # 2% margin on deposits\n",
        "\n",
        "df['Monthly_Revenue'] = avg_annual_revenue / 12\n",
        "df['Estimated_CLV_5yr'] = (\n",
        "    avg_annual_revenue * 5 +  # 5-year revenue horizon\n",
        "    df['Balance_ZAR'] * balance_margin\n",
        ")\n",
        "\n",
        "print(\"CLV Estimation:\")\n",
        "print(f\"  Mean CLV (5-year): R{df['Estimated_CLV_5yr'].mean():,.0f}\")\n",
        "print(f\"  Total customer base CLV: R{df['Estimated_CLV_5yr'].sum()/1_000_000:,.1f}M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHCxDFokli0z"
      },
      "source": [
        "## Section 4: Feature Selection\n",
        "\n",
        "Identifying which features to use for modeling. Excluding identifiers, redundant features, and zero-variance features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yeotntvqli0z",
        "outputId": "937d32b0-d61b-462a-e3f6-a33d83508be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total features for modeling: 57\n",
            "  Numerical: 44\n",
            "  Categorical: 13\n",
            "\n",
            "Numerical features (44):\n",
            "  - Age\n",
            "  - Tenure\n",
            "  - CreditScore\n",
            "  - NumOfProducts\n",
            "  - HasSavingsAccount\n",
            "  - HasChequeAccount\n",
            "  - HasCreditCard\n",
            "  - HasPersonalLoan\n",
            "  - HasHomeLoan\n",
            "  - HasVehicleFinance\n",
            "  ... and 34 more\n",
            "\n",
            "Categorical features (13):\n",
            "  - Gender (2 unique values)\n",
            "  - Province (9 unique values)\n",
            "  - AreaType (3 unique values)\n",
            "  - EducationLevel (5 unique values)\n",
            "  - EmploymentType (5 unique values)\n",
            "  - PreferredLanguage (11 unique values)\n",
            "  - AccountType (5 unique values)\n",
            "  - CreditRating (5 unique values)\n",
            "  - ProductName (4 unique values)\n",
            "  - SalaryPaymentMethod (3 unique values)\n",
            "  - PreferredCommChannel (5 unique values)\n",
            "  - Age_Group (6 unique values)\n",
            "  - Credit_Risk_Tier (4 unique values)\n"
          ]
        }
      ],
      "source": [
        "# Features to exclude\n",
        "exclude_features = [\n",
        "    # Identifiers\n",
        "    'RowNumber', 'CustomerId', 'Surname',\n",
        "    # Zero variance\n",
        "    'Bank', 'CreditBureau',\n",
        "    # Redundant\n",
        "    'HasCreditCard_Flag',  # Duplicate of HasCreditCard\n",
        "    'AgeBand',  # Using Age_Group instead\n",
        "    'MonthlySalary_ZAR',  # Using AnnualSalary_ZAR\n",
        "    # High cardinality with minimal value\n",
        "    'City',  # Province captures geographic risk better\n",
        "    # Target variable\n",
        "    'Churned'\n",
        "]\n",
        "\n",
        "# Separate numerical and categorical features\n",
        "all_features = [col for col in df.columns if col not in exclude_features]\n",
        "\n",
        "numerical_features = df[all_features].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = df[all_features].select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print(f\"Total features for modeling: {len(all_features)}\")\n",
        "print(f\"  Numerical: {len(numerical_features)}\")\n",
        "print(f\"  Categorical: {len(categorical_features)}\")\n",
        "\n",
        "print(f\"\\nNumerical features ({len(numerical_features)}):\")\n",
        "for feat in numerical_features[:10]:\n",
        "    print(f\"  - {feat}\")\n",
        "if len(numerical_features) > 10:\n",
        "    print(f\"  ... and {len(numerical_features) - 10} more\")\n",
        "\n",
        "print(f\"\\nCategorical features ({len(categorical_features)}):\")\n",
        "for feat in categorical_features:\n",
        "    print(f\"  - {feat} ({df[feat].nunique()} unique values)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMpQBBVBli0z"
      },
      "source": [
        "## Section 5: Train-Test Split\n",
        "\n",
        "Splitting data before any preprocessing to avoid data leakage. Using stratified split to maintain class balance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vgLdWcGli0z",
        "outputId": "eb178b2d-fa93-4192-9975-7951ab2a5f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-Test Split:\n",
            "  Training set: 8,000 samples (80.0%)\n",
            "  Test set: 2,000 samples (20.0%)\n",
            "\n",
            "Churn rate preserved:\n",
            "  Training: 20.4%\n",
            "  Test: 20.3%\n",
            "  Original: 20.4%\n"
          ]
        }
      ],
      "source": [
        "# Prepare X and y\n",
        "X = df[all_features].copy()\n",
        "y = df['Churned'].copy()\n",
        "\n",
        "# Stratified split (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train-Test Split:\")\n",
        "print(f\"  Training set: {len(X_train):,} samples ({len(X_train)/len(X):.1%})\")\n",
        "print(f\"  Test set: {len(X_test):,} samples ({len(X_test)/len(X):.1%})\")\n",
        "\n",
        "print(f\"\\nChurn rate preserved:\")\n",
        "print(f\"  Training: {y_train.mean():.1%}\")\n",
        "print(f\"  Test: {y_test.mean():.1%}\")\n",
        "print(f\"  Original: {y.mean():.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2s7VB7dli0z"
      },
      "source": [
        "## Section 6: Preprocessing Pipeline\n",
        "\n",
        "Building a scikit-learn pipeline for consistent transformation of numerical and categorical features. This ensures the same transformations apply to train, test, and future scoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQQ_m7Ejli00",
        "outputId": "0da16c08-12c9-4736-fbdc-518917613ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing pipeline created\n",
            "  Numerical features: 44 (impute + scale)\n",
            "  Categorical features: 13 (impute + one-hot encode)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Numerical pipeline: impute missing + scale\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical pipeline: impute missing + one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combined preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "print(\"Preprocessing pipeline created\")\n",
        "print(f\"  Numerical features: {len(numerical_features)} (impute + scale)\")\n",
        "print(f\"  Categorical features: {len(categorical_features)} (impute + one-hot encode)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZU-wiHqli00",
        "outputId": "46324b58-69a3-4ce5-b94b-53bc7e4f1452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessed:\n",
            "  Training shape: (8000, 98)\n",
            "  Test shape: (2000, 98)\n",
            "  Total features after encoding: 98\n"
          ]
        }
      ],
      "source": [
        "# Fit preprocessor on training data only\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "print(\"Data preprocessed:\")\n",
        "print(f\"  Training shape: {X_train_processed.shape}\")\n",
        "print(f\"  Test shape: {X_test_processed.shape}\")\n",
        "print(f\"  Total features after encoding: {X_train_processed.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSLhYGglli00"
      },
      "source": [
        "## Section 7: Save Prepared Data\n",
        "\n",
        "Saving the processed data and preprocessing pipeline for the modeling notebook. Also saving feature metadata for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A60Yx08uli00",
        "outputId": "4f07ff9c-c87c-40e3-f7fa-acb9292e5ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved:\n",
            "  ✓ X_train_processed.npy\n",
            "  ✓ X_test_processed.npy\n",
            "  ✓ y_train.npy\n",
            "  ✓ y_test.npy\n",
            "  ✓ preprocessor.pkl\n",
            "  ✓ feature_metadata.pkl\n",
            "  ✓ test_set_metadata.csv\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save preprocessed data\n",
        "np.save('X_train_processed.npy', X_train_processed)\n",
        "np.save('X_test_processed.npy', X_test_processed)\n",
        "np.save('y_train.npy', y_train.values)\n",
        "np.save('y_test.npy', y_test.values)\n",
        "\n",
        "# Save preprocessor\n",
        "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
        "\n",
        "# Save feature names\n",
        "feature_metadata = {\n",
        "    'numerical_features': numerical_features,\n",
        "    'categorical_features': categorical_features,\n",
        "    'all_features': all_features\n",
        "}\n",
        "joblib.dump(feature_metadata, 'feature_metadata.pkl')\n",
        "\n",
        "# Save original test set with IDs for business analysis\n",
        "test_indices = X_test.index\n",
        "test_data_with_target = df.loc[test_indices, ['CustomerId', 'Estimated_CLV_5yr', 'Churned']].copy()\n",
        "test_data_with_target.to_csv('test_set_metadata.csv', index=True)\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\"  ✓ X_train_processed.npy\")\n",
        "print(\"  ✓ X_test_processed.npy\")\n",
        "print(\"  ✓ y_train.npy\")\n",
        "print(\"  ✓ y_test.npy\")\n",
        "print(\"  ✓ preprocessor.pkl\")\n",
        "print(\"  ✓ feature_metadata.pkl\")\n",
        "print(\"  ✓ test_set_metadata.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the engineered dataset with all features\n",
        "df.to_csv('FNB_Churn_Engineered_Features.csv', index=False)\n",
        "\n",
        "print(\"✓ Saved: FNB_Churn_Engineered_Features.csv\")\n",
        "print(f\"  Rows: {df.shape[0]:,}\")\n",
        "print(f\"  Columns: {df.shape[1]}\")\n",
        "print(f\"  Original features: 43\")\n",
        "print(f\"  Total features: {df.shape[1]}\")\n",
        "print(f\"  New engineered features: {df.shape[1] - 43}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BZXnTiUmZDA",
        "outputId": "3916afa6-8461-45b8-98df-73b2020abeb9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Saved: FNB_Churn_Engineered_Features.csv\n",
            "  Rows: 10,000\n",
            "  Columns: 67\n",
            "  Original features: 43\n",
            "  Total features: 67\n",
            "  New engineered features: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMCFCT3Qli00"
      },
      "source": [
        "## Summary\n",
        "\n",
        "**Features Created**: 25+ engineered features based on EDA insights\n",
        "\n",
        "**Key Feature Groups**:\n",
        "- Age risk indicators (strongest predictor)\n",
        "- Product complexity scores (U-shaped pattern)\n",
        "- Geographic risk flags (provincial concentration)\n",
        "- Financial ratios and wealth indicators\n",
        "- Engagement and activity metrics\n",
        "- Composite risk score\n",
        "- Customer lifetime value estimation\n",
        "\n",
        "**Data Prepared**:\n",
        "- Training set: 8,000 customers (20.4% churn)\n",
        "- Test set: 2,000 customers (20.4% churn)\n",
        "- Features: 60+ after one-hot encoding\n",
        "\n",
        "**Next Steps**: Model development in Notebook 04 using these engineered features."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}